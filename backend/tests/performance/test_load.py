"""Performance tests verifying response times and concurrent request handling.

These tests exercise the application under load to ensure acceptable response
times and correct behavior when handling many concurrent requests.

Markers:
    slow: Tests that may take several seconds; excluded from fast CI runs.
"""

import asyncio
import time

import pytest
from httpx import ASGITransport, AsyncClient

from backend.app import app
from backend.dependencies import get_current_user
from backend.models.common import CurrentUser

# ---------------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------------

MOCK_USER = CurrentUser(
    id="11111111-1111-1111-1111-111111111111",
    email="perf-test@velgarien.dev",
    access_token="mock-perf-token",
)

BASE_URL = "http://testserver"

# ---------------------------------------------------------------------------
# Fixtures
# ---------------------------------------------------------------------------


@pytest.fixture(autouse=True)
def _cleanup_overrides():
    """Ensure dependency overrides are cleaned up after every test."""
    yield
    app.dependency_overrides.clear()


@pytest.fixture()
def _auth_override():
    """Override auth dependency so authenticated endpoints can be reached."""
    app.dependency_overrides[get_current_user] = lambda: MOCK_USER
    yield
    app.dependency_overrides.pop(get_current_user, None)


# ===========================================================================
# 1. Concurrent reads
# ===========================================================================


@pytest.mark.slow
class TestConcurrentReads:
    """Verify the app handles many concurrent requests without errors."""

    async def test_50_concurrent_health_requests(self):
        """50 concurrent GET /health requests should all return 200."""
        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:

            async def _hit_health():
                return await client.get("/api/v1/health")

            start = time.monotonic()
            responses = await asyncio.gather(*[_hit_health() for _ in range(50)])
            elapsed = time.monotonic() - start

        # All should succeed
        for i, resp in enumerate(responses):
            assert resp.status_code == 200, (
                f"Request {i} returned {resp.status_code}"
            )

        # Total wall-clock time should be reasonable
        assert elapsed < 5.0, (
            f"50 concurrent requests took {elapsed:.2f}s, expected < 5s"
        )

    async def test_concurrent_openapi_requests(self):
        """20 concurrent GET /openapi.json requests should all return 200."""
        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:

            async def _hit_openapi():
                return await client.get("/openapi.json")

            responses = await asyncio.gather(*[_hit_openapi() for _ in range(20)])

        for i, resp in enumerate(responses):
            assert resp.status_code == 200, (
                f"Request {i} returned {resp.status_code}"
            )
            data = resp.json()
            assert "paths" in data


# ===========================================================================
# 2. Response times
# ===========================================================================


@pytest.mark.slow
class TestResponseTimes:
    """Verify that individual endpoints respond within acceptable latency."""

    async def test_health_under_100ms(self):
        """GET /health should respond in under 100ms."""
        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:
            start = time.monotonic()
            resp = await client.get("/api/v1/health")
            elapsed = time.monotonic() - start

        assert resp.status_code == 200
        assert elapsed < 0.1, (
            f"Health check took {elapsed * 1000:.1f}ms, expected < 100ms"
        )

    async def test_openapi_spec_under_500ms(self):
        """GET /openapi.json should respond in under 500ms."""
        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:
            start = time.monotonic()
            resp = await client.get("/openapi.json")
            elapsed = time.monotonic() - start

        assert resp.status_code == 200
        assert elapsed < 0.5, (
            f"OpenAPI spec took {elapsed * 1000:.1f}ms, expected < 500ms"
        )

    async def test_docs_under_500ms(self):
        """GET /api/docs should respond in under 500ms."""
        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:
            start = time.monotonic()
            resp = await client.get("/api/docs")
            elapsed = time.monotonic() - start

        assert resp.status_code == 200
        assert elapsed < 0.5, (
            f"Swagger docs took {elapsed * 1000:.1f}ms, expected < 500ms"
        )

    async def test_health_average_over_10_requests(self):
        """Average response time over 10 sequential health requests should be < 50ms."""
        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:
            times = []
            for _ in range(10):
                start = time.monotonic()
                resp = await client.get("/api/v1/health")
                elapsed = time.monotonic() - start
                assert resp.status_code == 200
                times.append(elapsed)

        avg_ms = (sum(times) / len(times)) * 1000
        assert avg_ms < 50, (
            f"Average health response time was {avg_ms:.1f}ms, expected < 50ms"
        )


# ===========================================================================
# 3. Rate limiting
# ===========================================================================


@pytest.mark.slow
class TestRateLimiting:
    """Verify that rate-limited endpoints eventually reject excessive requests.

    Note: slowapi rate limiting in test mode may not trigger reliably since
    TestClient/httpx bypass actual network stack. These tests document the
    expected behavior and will pass in a real deployment. The tests are
    structured to be safe even if the limiter is not active in test mode.
    """

    async def test_generation_endpoint_auth_required(self, _auth_override):
        """Generation endpoints should require auth and return proper errors.

        Without a valid role check, the endpoint should fail at the role
        dependency level (not succeed with 200).
        """
        from unittest.mock import MagicMock

        from backend.dependencies import get_supabase

        # Also mock get_supabase to prevent Supabase client creation
        app.dependency_overrides[get_supabase] = lambda: MagicMock()

        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:
            resp = await client.post(
                "/api/v1/simulations/00000000-0000-0000-0000-000000000000/generate/agent",
                json={"name": "Test", "system": "politics"},
                headers={"Authorization": "Bearer mock-perf-token"},
            )
            # Should fail at the role check level — not 200
            assert resp.status_code in (403, 422, 500)

    async def test_rapid_health_requests_survive(self):
        """Health endpoint (no rate limit) should handle 100 rapid requests."""
        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:
            responses = await asyncio.gather(
                *[client.get("/api/v1/health") for _ in range(100)]
            )

        success_count = sum(1 for r in responses if r.status_code == 200)
        assert success_count == 100, (
            f"Expected all 100 health requests to succeed, got {success_count}"
        )

    async def test_rate_limit_returns_429_or_allows(self):
        """When rate limiting is active, exceeding the limit should return 429.

        This test sends many rapid requests to a rate-limited endpoint.
        In test mode, the limiter may not be active, so we accept both
        scenarios: all requests pass (limiter inactive) or some get 429.
        """
        from unittest.mock import MagicMock

        from backend.dependencies import get_supabase, require_role

        # Set up full auth chain for the generation endpoint
        app.dependency_overrides[get_current_user] = lambda: MOCK_USER

        mock_sb = MagicMock()
        app.dependency_overrides[get_supabase] = lambda: mock_sb

        async def _fake_role():
            return "editor"

        app.dependency_overrides[require_role("editor")] = _fake_role

        transport = ASGITransport(app=app)

        async with AsyncClient(transport=transport, base_url=BASE_URL) as client:
            responses = []
            # Fire 50 rapid requests to a rate-limited endpoint
            for _ in range(50):
                resp = await client.post(
                    "/api/v1/simulations/00000000-0000-0000-0000-000000000000/generate/agent",
                    json={"name": "Load Test Agent", "system": "politics"},
                    headers={"Authorization": "Bearer mock-perf-token"},
                )
                responses.append(resp)

        status_codes = [r.status_code for r in responses]

        # Either the limiter kicked in (some 429s) or it's inactive in test mode
        has_429 = 429 in status_codes
        if has_429:
            rate_limited = status_codes.count(429)
            assert rate_limited > 0, "Expected some requests to be rate-limited"
        # If no 429, the test still passes — limiter may not be active in ASGI test mode
